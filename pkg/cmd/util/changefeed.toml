# 指定配置文件中涉及的库名、表名是否为大小写敏感的
# 该配置会同时影响 filter 和 sink 相关配置，默认为 true

# Specify whether the schema name and table name in this configuration file are case sensitive
# This configuration will affect both filter and sink related configurations, the default is true
case-sensitive = true

[filter]
# 忽略哪些 StartTs 的事务
# Transactions with the following StartTs will be ignored
ignore-txn-start-ts = [1, 2]

# 过滤器规则
# 过滤规则语法：https://docs.pingcap.com/zh/tidb/stable/table-filter#%E8%A1%A8%E5%BA%93%E8%BF%87%E6%BB%A4%E8%AF%AD%E6%B3%95
# The rules of the filter
# Filter rules syntax: https://docs.pingcap.com/tidb/stable/table-filter#syntax
rules = ['*.*', '!test.*']

[mounter]
# mounter 线程数
# the thread number of the the mounter
worker-num = 16

[sink]
# 对于 MQ 类的 Sink，可以通过 dispatchers 配置 event 分发器
# 分发器支持 default, ts, rowid, table 四种
# For MQ Sinks, you can configure event distribution rules through dispatchers
# Dispatchers support default, ts, rowid and table
dispatchers = [
    { matcher = ['test1.*', 'test2.*'], partition = "ts", topic = "hello_{schema}" },
    { matcher = ['test3.*', 'test4.*'], dispatcher = "rowid", topic = "{schema}_world" },
]
# 对于 MQ 类的 Sink，可以通过 column-selectors 配置 column 选择器
# For MQ Sinks, you can configure column selector rules through column-selectors
column-selectors = [
    { matcher = ['test1.*', 'test2.*'], columns = ["column1", "column2"] },
    { matcher = ['test3.*', 'test4.*'], columns = ["!a", "column3"] },
]
# 对于 MQ 类的 Sink，可以指定消息的协议格式
# 协议目前支持 open-protocol, canal, canal-json, avro 和 maxwell 五种。
# For MQ Sinks, you can configure the protocol of the messages sending to MQ
# Currently the protocol support open-protocol, canal, canal-json, avro and maxwell.
protocol = "open-protocol"

[consistent]
# 一致性级别，none 为默认，非灾难场景，提供 finished-ts 情况下的最终一致性；eventual 使用 redo log，提供上游灾难情况下的最终一致性
# consistent level, none is the default value.
# none: eventual consistent support in non-disaster scenario(should provide a finished-ts)
# eventual: eventual consistent in disaster scenario
level = "none"
# 单个 redo log 文件大小，单位 MB
# file size of single redo log, unit is MB
max-log-size = 64
# 刷新或上传 redo log 至 S3 的间隔，单位毫秒
# interval to flush or upload redo log, default is 1000ms, unit is microseconds
flush-interval = 1000
# 存储 redo log 的形式，包括 nfs（NFS 目录），S3（上传至S3），blackhole（测试用）
# storage type for redo log
# nfs: store redo logs in nfs directly
# s3: upload redo logs to s3 storage
# blackhole: used for test only
storage = "s3://logbucket/test-changefeed?endpoint=http://$S3_ENDPOINT/"
