/**
 * This file is AUTO GENERATED by [msw-auto-mock](https://github.com/zoubingwu/msw-auto-mock)
 * Feel free to commit/edit it as you need.
 */
/* eslint-disable */
/* tslint:disable */
import { setupWorker, rest } from 'msw'
import faker from '@faker-js/faker'

faker.seed(1)

const baseURL = ''
const MAX_ARRAY_LENGTH = 20

const gen = (function* () {
  let i = 0
  while (true) {
    if (i === Number.MAX_SAFE_INTEGER - 1) {
      i = 0
    }
    yield i++
  }
})()

export const handlers = [
  rest.get(`${baseURL}/api/v1/docs`, (req, res, ctx) => {
    const resultArray = [[ctx.status(200), ctx.json(null)]]

    return res(...resultArray[gen.next().value % resultArray.length])
  }),
  rest.get(`${baseURL}/api/v1/dm.json`, (req, res, ctx) => {
    const resultArray = [[ctx.status(200), ctx.json(null)]]

    return res(...resultArray[gen.next().value % resultArray.length])
  }),
  rest.post(`${baseURL}/api/v1/sources`, (req, res, ctx) => {
    const resultArray = [
      [
        ctx.status(201),
        ctx.json({
          source_name: 'mysql-01' + '_' + faker.datatype.uuid(),
          host: '127.0.0.1',
          port: 3306,
          user: 'root',
          password: '123456',
          enable_gtid: faker.datatype.boolean(),
          enable: faker.datatype.boolean(),
          flavor: 'mysql',
          task_name_list: [
            ...new Array(
              faker.datatype.number({ max: MAX_ARRAY_LENGTH })
            ).keys(),
          ].map(_ => 'task1'),
          security: {
            ssl_ca_content: faker.lorem.slug(1),
            ssl_cert_content: faker.lorem.slug(1),
            ssl_key_content: faker.lorem.slug(1),
            cert_allowed_cn: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => faker.lorem.slug(1)),
          },
          purge: {
            interval: faker.datatype.number(),
            expires: faker.datatype.number(),
            remain_space: faker.datatype.number(),
          },
          status_list: [
            ...new Array(
              faker.datatype.number({ max: MAX_ARRAY_LENGTH })
            ).keys(),
          ].map(_ => ({
            source_name: 'mysql-replica-01',
            worker_name: 'worker-1',
            relay_status: {
              master_binlog: '(mysql-bin.000001, 1979)',
              master_binlog_gtid: 'e9a1fc22-ec08-11e9-b2ac-0242ac110003:1-7849',
              relay_dir: './sub_dir',
              relay_binlog_gtid: 'e9a1fc22-ec08-11e9-b2ac-0242ac110003:1-7849',
              relay_catch_up_master: faker.datatype.boolean(),
              stage: 'Running',
            },
            error_msg: faker.lorem.slug(1),
          })),
          relay_config: {
            enable_relay: faker.datatype.boolean(),
            relay_binlog_name: 'mysql-bin.000002',
            relay_binlog_gtid: 'e9a1fc22-ec08-11e9-b2ac-0242ac110003:1-7849',
            relay_dir: faker.lorem.slug(1),
          },
        }),
      ],
      [
        ctx.status(400),
        ctx.json({
          error_msg: faker.lorem.slug(1),
          error_code: faker.datatype.number(),
        }),
      ],
    ]

    return res(...resultArray[gen.next().value % resultArray.length])
  }),
  rest.get(`${baseURL}/api/v1/sources`, (req, res, ctx) => {
    const resultArray = [
      [
        ctx.status(200),
        ctx.json({
          total: faker.datatype.number(),
          data: [
            ...new Array(
              faker.datatype.number({ max: MAX_ARRAY_LENGTH })
            ).keys(),
          ].map(_ => ({
            source_name: 'mysql-01',
            host: '127.0.0.1',
            port: 3306,
            user: 'root',
            password: '123456',
            enable_gtid: faker.datatype.boolean(),
            enable: faker.datatype.boolean(),
            flavor: 'mysql',
            task_name_list: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => 'task1'),
            security: {
              ssl_ca_content: faker.lorem.slug(1),
              ssl_cert_content: faker.lorem.slug(1),
              ssl_key_content: faker.lorem.slug(1),
              cert_allowed_cn: [
                ...new Array(
                  faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                ).keys(),
              ].map(_ => faker.lorem.slug(1)),
            },
            purge: {
              interval: faker.datatype.number(),
              expires: faker.datatype.number(),
              remain_space: faker.datatype.number(),
            },
            status_list: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => ({
              source_name: 'mysql-replica-01',
              worker_name: 'worker-1',
              relay_status: {
                master_binlog: '(mysql-bin.000001, 1979)',
                master_binlog_gtid:
                  'e9a1fc22-ec08-11e9-b2ac-0242ac110003:1-7849',
                relay_dir: './sub_dir',
                relay_binlog_gtid:
                  'e9a1fc22-ec08-11e9-b2ac-0242ac110003:1-7849',
                relay_catch_up_master: faker.datatype.boolean(),
                stage: 'Running',
              },
              error_msg: faker.lorem.slug(1),
            })),
            relay_config: {
              enable_relay: faker.datatype.boolean(),
              relay_binlog_name: 'mysql-bin.000002',
              relay_binlog_gtid: 'e9a1fc22-ec08-11e9-b2ac-0242ac110003:1-7849',
              relay_dir: faker.lorem.slug(1),
            },
          })),
        }),
      ],
    ]

    return res(...resultArray[gen.next().value % resultArray.length])
  }),
  rest.get(`${baseURL}/api/v1/sources/:sourceName`, (req, res, ctx) => {
    const resultArray = [
      [
        ctx.status(200),
        ctx.json({
          source_name: 'mysql-01',
          host: '127.0.0.1',
          port: 3306,
          user: 'root',
          password: '123456',
          enable_gtid: faker.datatype.boolean(),
          enable: faker.datatype.boolean(),
          flavor: 'mysql',
          task_name_list: [
            ...new Array(
              faker.datatype.number({ max: MAX_ARRAY_LENGTH })
            ).keys(),
          ].map(_ => 'task1'),
          security: {
            ssl_ca_content: faker.lorem.slug(1),
            ssl_cert_content: faker.lorem.slug(1),
            ssl_key_content: faker.lorem.slug(1),
            cert_allowed_cn: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => faker.lorem.slug(1)),
          },
          purge: {
            interval: faker.datatype.number(),
            expires: faker.datatype.number(),
            remain_space: faker.datatype.number(),
          },
          status_list: [
            ...new Array(
              faker.datatype.number({ max: MAX_ARRAY_LENGTH })
            ).keys(),
          ].map(_ => ({
            source_name: 'mysql-replica-01',
            worker_name: 'worker-1',
            relay_status: {
              master_binlog: '(mysql-bin.000001, 1979)',
              master_binlog_gtid: 'e9a1fc22-ec08-11e9-b2ac-0242ac110003:1-7849',
              relay_dir: './sub_dir',
              relay_binlog_gtid: 'e9a1fc22-ec08-11e9-b2ac-0242ac110003:1-7849',
              relay_catch_up_master: faker.datatype.boolean(),
              stage: 'Running',
            },
            error_msg: faker.lorem.slug(1),
          })),
          relay_config: {
            enable_relay: faker.datatype.boolean(),
            relay_binlog_name: 'mysql-bin.000002',
            relay_binlog_gtid: 'e9a1fc22-ec08-11e9-b2ac-0242ac110003:1-7849',
            relay_dir: faker.lorem.slug(1),
          },
        }),
      ],
      [ctx.status(404), ctx.json(null)],
    ]

    return res(...resultArray[gen.next().value % resultArray.length])
  }),
  rest.delete(`${baseURL}/api/v1/sources/:sourceName`, (req, res, ctx) => {
    const resultArray = [
      [ctx.status(204), ctx.json(null)],
      [
        ctx.status(400),
        ctx.json({
          error_msg: faker.lorem.slug(1),
          error_code: faker.datatype.number(),
        }),
      ],
    ]

    return res(...resultArray[gen.next().value % resultArray.length])
  }),
  rest.put(`${baseURL}/api/v1/sources/:sourceName`, (req, res, ctx) => {
    const resultArray = [
      [
        ctx.status(200),
        ctx.json({
          source_name: 'mysql-01',
          host: '127.0.0.1',
          port: 3306,
          user: 'root',
          password: '123456',
          enable_gtid: faker.datatype.boolean(),
          enable: faker.datatype.boolean(),
          flavor: 'mysql',
          task_name_list: [
            ...new Array(
              faker.datatype.number({ max: MAX_ARRAY_LENGTH })
            ).keys(),
          ].map(_ => 'task1'),
          security: {
            ssl_ca_content: faker.lorem.slug(1),
            ssl_cert_content: faker.lorem.slug(1),
            ssl_key_content: faker.lorem.slug(1),
            cert_allowed_cn: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => faker.lorem.slug(1)),
          },
          purge: {
            interval: faker.datatype.number(),
            expires: faker.datatype.number(),
            remain_space: faker.datatype.number(),
          },
          status_list: [
            ...new Array(
              faker.datatype.number({ max: MAX_ARRAY_LENGTH })
            ).keys(),
          ].map(_ => ({
            source_name: 'mysql-replica-01',
            worker_name: 'worker-1',
            relay_status: {
              master_binlog: '(mysql-bin.000001, 1979)',
              master_binlog_gtid: 'e9a1fc22-ec08-11e9-b2ac-0242ac110003:1-7849',
              relay_dir: './sub_dir',
              relay_binlog_gtid: 'e9a1fc22-ec08-11e9-b2ac-0242ac110003:1-7849',
              relay_catch_up_master: faker.datatype.boolean(),
              stage: 'Running',
            },
            error_msg: faker.lorem.slug(1),
          })),
          relay_config: {
            enable_relay: faker.datatype.boolean(),
            relay_binlog_name: 'mysql-bin.000002',
            relay_binlog_gtid: 'e9a1fc22-ec08-11e9-b2ac-0242ac110003:1-7849',
            relay_dir: faker.lorem.slug(1),
          },
        }),
      ],
      [
        ctx.status(400),
        ctx.json({
          error_msg: faker.lorem.slug(1),
          error_code: faker.datatype.number(),
        }),
      ],
    ]

    return res(...resultArray[gen.next().value % resultArray.length])
  }),
  rest.get(`${baseURL}/api/v1/sources/:sourceName/status`, (req, res, ctx) => {
    const resultArray = [
      [
        ctx.status(200),
        ctx.json({
          total: faker.datatype.number(),
          data: [
            ...new Array(
              faker.datatype.number({ max: MAX_ARRAY_LENGTH })
            ).keys(),
          ].map(_ => ({
            source_name: 'mysql-replica-01',
            worker_name: 'worker-1',
            relay_status: {
              master_binlog: '(mysql-bin.000001, 1979)',
              master_binlog_gtid: 'e9a1fc22-ec08-11e9-b2ac-0242ac110003:1-7849',
              relay_dir: './sub_dir',
              relay_binlog_gtid: 'e9a1fc22-ec08-11e9-b2ac-0242ac110003:1-7849',
              relay_catch_up_master: faker.datatype.boolean(),
              stage: 'Running',
            },
            error_msg: faker.lorem.slug(1),
          })),
        }),
      ],
      [
        ctx.status(400),
        ctx.json({
          error_msg: faker.lorem.slug(1),
          error_code: faker.datatype.number(),
        }),
      ],
    ]

    return res(...resultArray[gen.next().value % resultArray.length])
  }),
  rest.post(`${baseURL}/api/v1/sources/:sourceName/enable`, (req, res, ctx) => {
    const resultArray = [
      [ctx.status(200), ctx.json(null)],
      [
        ctx.status(400),
        ctx.json({
          error_msg: faker.lorem.slug(1),
          error_code: faker.datatype.number(),
        }),
      ],
    ]

    return res(...resultArray[gen.next().value % resultArray.length])
  }),
  rest.post(
    `${baseURL}/api/v1/sources/:sourceName/disable`,
    (req, res, ctx) => {
      const resultArray = [
        [ctx.status(200), ctx.json(null)],
        [
          ctx.status(400),
          ctx.json({
            error_msg: faker.lorem.slug(1),
            error_code: faker.datatype.number(),
          }),
        ],
      ]

      return res(...resultArray[gen.next().value % resultArray.length])
    }
  ),
  rest.post(
    `${baseURL}/api/v1/sources/:sourceName/transfer`,
    (req, res, ctx) => {
      const resultArray = [
        [ctx.status(200), ctx.json(null)],
        [
          ctx.status(400),
          ctx.json({
            error_msg: faker.lorem.slug(1),
            error_code: faker.datatype.number(),
          }),
        ],
      ]

      return res(...resultArray[gen.next().value % resultArray.length])
    }
  ),
  rest.post(
    `${baseURL}/api/v1/sources/:sourceName/relay/enable`,
    (req, res, ctx) => {
      const resultArray = [
        [ctx.status(200), ctx.json(null)],
        [
          ctx.status(400),
          ctx.json({
            error_msg: faker.lorem.slug(1),
            error_code: faker.datatype.number(),
          }),
        ],
      ]

      return res(...resultArray[gen.next().value % resultArray.length])
    }
  ),
  rest.post(
    `${baseURL}/api/v1/sources/:sourceName/relay/disable`,
    (req, res, ctx) => {
      const resultArray = [
        [ctx.status(200), ctx.json(null)],
        [
          ctx.status(400),
          ctx.json({
            error_msg: faker.lorem.slug(1),
            error_code: faker.datatype.number(),
          }),
        ],
      ]

      return res(...resultArray[gen.next().value % resultArray.length])
    }
  ),
  rest.post(
    `${baseURL}/api/v1/sources/:sourceName/relay/purge`,
    (req, res, ctx) => {
      const resultArray = [
        [ctx.status(200), ctx.json(null)],
        [
          ctx.status(400),
          ctx.json({
            error_msg: faker.lorem.slug(1),
            error_code: faker.datatype.number(),
          }),
        ],
      ]

      return res(...resultArray[gen.next().value % resultArray.length])
    }
  ),
  rest.get(`${baseURL}/api/v1/sources/:sourceName/schemas`, (req, res, ctx) => {
    const resultArray = [
      [
        ctx.status(200),
        ctx.json(
          [
            ...new Array(
              faker.datatype.number({ max: MAX_ARRAY_LENGTH })
            ).keys(),
          ].map(_ => 'db1')
        ),
      ],
      [
        ctx.status(400),
        ctx.json({
          error_msg: faker.lorem.slug(1),
          error_code: faker.datatype.number(),
        }),
      ],
    ]

    return res(...resultArray[gen.next().value % resultArray.length])
  }),
  rest.get(
    `${baseURL}/api/v1/sources/:sourceName/schemas/:schemaName`,
    (req, res, ctx) => {
      const resultArray = [
        [
          ctx.status(200),
          ctx.json(
            [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => 'table1')
          ),
        ],
        [
          ctx.status(400),
          ctx.json({
            error_msg: faker.lorem.slug(1),
            error_code: faker.datatype.number(),
          }),
        ],
      ]

      return res(...resultArray[gen.next().value % resultArray.length])
    }
  ),
  rest.post(`${baseURL}/api/v1/tasks`, (req, res, ctx) => {
    const resultArray = [
      [
        ctx.status(201),
        ctx.json({
          task: {
            name: 'task-1',
            task_mode: 'all',
            shard_mode: faker.random.arrayElement([
              'pessimistic',
              'optimistic',
            ]),
            meta_schema: 'dm-meta',
            enhance_online_schema_change: true,
            on_duplicate: faker.random.arrayElement([
              'replace',
              'error',
              'ignore',
            ]),
            target_config: {
              host: '127.0.0.1',
              port: 3306,
              user: 'root',
              password: '123456',
              security: {
                ssl_ca_content: faker.lorem.slug(1),
                ssl_cert_content: faker.lorem.slug(1),
                ssl_key_content: faker.lorem.slug(1),
                cert_allowed_cn: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => faker.lorem.slug(1)),
              },
            },
            binlog_filter_rule: [...new Array(5).keys()]
              .map(_ => ({
                [faker.lorem.word()]: {
                  ignore_event: [
                    ...new Array(
                      faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                    ).keys(),
                  ].map(_ => 'all dml'),
                  ignore_sql: [
                    ...new Array(
                      faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                    ).keys(),
                  ].map(_ => '^Drop'),
                },
              }))
              .reduce((acc, next) => Object.assign(acc, next), {}),
            table_migrate_rule: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => ({
              source: {
                source_name: 'source-name',
                schema: 'db-*',
                table: 'tb-*',
              },
              target: {
                schema: 'db1',
                table: 'tb1',
              },
              binlog_filter_rule: [
                ...new Array(
                  faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                ).keys(),
              ].map(_ => 'rule-1'),
            })),
            source_config: {
              full_migrate_conf: {
                export_threads: faker.datatype.number(),
                import_threads: faker.datatype.number(),
                data_dir: './exported_data',
                consistency: 'auto',
              },
              incr_migrate_conf: {
                repl_threads: faker.datatype.number(),
                repl_batch: faker.datatype.number(),
              },
              source_conf: [
                ...new Array(
                  faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                ).keys(),
              ].map(_ => ({
                source_name: 'mysql-replica-01',
                binlog_name: 'binlog.000001',
                binlog_pos: 4,
                binlog_gtid:
                  '03fc0263-28c7-11e7-a653-6c0b84d59f30:1-7041423,05474d3c-28c7-11e7-8352-203db246dd3d:1-170',
              })),
            },
            status_list: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => ({
              name: faker.name.findName(),
              source_name: faker.name.findName(),
              worker_name: faker.name.findName(),
              stage: faker.random.arrayElement([
                'Stopped',
                'Running',
                'Finished',
              ]),
              unit: 'sync',
              unresolved_ddl_lock_id: faker.lorem.slug(1),
              load_status: {
                finished_bytes: faker.datatype.number(),
                total_bytes: faker.datatype.number(),
                progress: faker.lorem.slug(1),
                meta_binlog: faker.lorem.slug(1),
                meta_binlog_gtid: faker.lorem.slug(1),
              },
              sync_status: {
                total_events: faker.datatype.number(),
                total_tps: faker.datatype.number(),
                recent_tps: faker.datatype.number(),
                master_binlog: faker.lorem.slug(1),
                master_binlog_gtid: faker.lorem.slug(1),
                syncer_binlog: faker.lorem.slug(1),
                syncer_binlog_gtid: faker.lorem.slug(1),
                blocking_ddls: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => faker.lorem.slug(1)),
                unresolved_groups: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => ({
                  target: faker.lorem.slug(1),
                  ddl_list: [
                    ...new Array(
                      faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                    ).keys(),
                  ].map(_ => faker.lorem.slug(1)),
                  first_location: faker.lorem.slug(1),
                  synced: [
                    ...new Array(
                      faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                    ).keys(),
                  ].map(_ => faker.lorem.slug(1)),
                  unsynced: [
                    ...new Array(
                      faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                    ).keys(),
                  ].map(_ => faker.lorem.slug(1)),
                })),
                synced: faker.datatype.boolean(),
                binlog_type: faker.lorem.slug(1),
                seconds_behind_master: faker.datatype.number(),
              },
              dump_status: {
                total_tables: faker.datatype.number(),
                completed_tables: faker.datatype.number(),
                finished_bytes: faker.datatype.number(),
                finished_rows: faker.datatype.number(),
                estimate_total_rows: faker.datatype.number(),
              },
              error_msg: faker.lorem.slug(1),
            })),
            ignore_checking_items: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => 'version'),
          },
          check_result: 'pre-check is passed. ',
        }),
      ],
      [
        ctx.status(400),
        ctx.json({
          error_msg: faker.lorem.slug(1),
          error_code: faker.datatype.number(),
        }),
      ],
    ]

    return res(...resultArray[gen.next().value % resultArray.length])
  }),
  rest.get(`${baseURL}/api/v1/tasks`, (req, res, ctx) => {
    const resultArray = [
      [
        ctx.status(200),
        ctx.json({
          total: faker.datatype.number(),
          data: [
            ...new Array(
              faker.datatype.number({ max: MAX_ARRAY_LENGTH })
            ).keys(),
          ].map(_ => ({
            name: 'task-1' + '_' + faker.lorem.slug(),
            task_mode: 'all',
            shard_mode: faker.random.arrayElement([
              'pessimistic',
              'optimistic',
            ]),
            meta_schema: 'dm-meta',
            enhance_online_schema_change: true,
            on_duplicate: faker.random.arrayElement([
              'replace',
              'error',
              'ignore',
            ]),
            target_config: {
              host: '127.0.0.1',
              port: 3306,
              user: 'root',
              password: '123456',
              security: {
                ssl_ca_content: faker.lorem.slug(1),
                ssl_cert_content: faker.lorem.slug(1),
                ssl_key_content: faker.lorem.slug(1),
                cert_allowed_cn: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => faker.lorem.slug(1)),
              },
            },
            binlog_filter_rule: [...new Array(5).keys()]
              .map(_ => ({
                [faker.lorem.word()]: {
                  ignore_event: [
                    ...new Array(
                      faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                    ).keys(),
                  ].map(_ => 'all dml'),
                  ignore_sql: [
                    ...new Array(
                      faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                    ).keys(),
                  ].map(_ => '^Drop'),
                },
              }))
              .reduce((acc, next) => Object.assign(acc, next), {}),
            table_migrate_rule: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => ({
              source: {
                source_name: 'source-name',
                schema: 'db-*',
                table: 'tb-*',
              },
              target: {
                schema: 'db1',
                table: 'tb1',
              },
              binlog_filter_rule: [
                ...new Array(
                  faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                ).keys(),
              ].map(_ => 'rule-1'),
            })),
            source_config: {
              full_migrate_conf: {
                export_threads: faker.datatype.number(),
                import_threads: faker.datatype.number(),
                data_dir: './exported_data',
                consistency: 'auto',
              },
              incr_migrate_conf: {
                repl_threads: faker.datatype.number(),
                repl_batch: faker.datatype.number(),
              },
              source_conf: [
                ...new Array(
                  faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                ).keys(),
              ].map(_ => ({
                source_name: 'mysql-replica-01',
                binlog_name: 'binlog.000001',
                binlog_pos: 4,
                binlog_gtid:
                  '03fc0263-28c7-11e7-a653-6c0b84d59f30:1-7041423,05474d3c-28c7-11e7-8352-203db246dd3d:1-170',
              })),
            },
            status_list: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => ({
              name: faker.name.findName(),
              source_name: faker.name.findName(),
              worker_name: faker.name.findName(),
              stage: faker.random.arrayElement([
                'Stopped',
                'Running',
                'Finished',
              ]),
              unit: 'sync',
              unresolved_ddl_lock_id: faker.lorem.slug(1),
              load_status: {
                finished_bytes: faker.datatype.number(),
                total_bytes: faker.datatype.number(),
                progress: faker.lorem.slug(1),
                meta_binlog: faker.lorem.slug(1),
                meta_binlog_gtid: faker.lorem.slug(1),
              },
              sync_status: {
                total_events: faker.datatype.number(),
                total_tps: faker.datatype.number(),
                recent_tps: faker.datatype.number(),
                master_binlog: faker.lorem.slug(1),
                master_binlog_gtid: faker.lorem.slug(1),
                syncer_binlog: faker.lorem.slug(1),
                syncer_binlog_gtid: faker.lorem.slug(1),
                blocking_ddls: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => faker.lorem.slug(1)),
                unresolved_groups: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => ({
                  target: faker.lorem.slug(1),
                  ddl_list: [
                    ...new Array(
                      faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                    ).keys(),
                  ].map(_ => faker.lorem.slug(1)),
                  first_location: faker.lorem.slug(1),
                  synced: [
                    ...new Array(
                      faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                    ).keys(),
                  ].map(_ => faker.lorem.slug(1)),
                  unsynced: [
                    ...new Array(
                      faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                    ).keys(),
                  ].map(_ => faker.lorem.slug(1)),
                })),
                synced: faker.datatype.boolean(),
                binlog_type: faker.lorem.slug(1),
                seconds_behind_master: faker.datatype.number(),
              },
              dump_status: {
                total_tables: faker.datatype.number(),
                completed_tables: faker.datatype.number(),
                finished_bytes: faker.datatype.number(),
                finished_rows: faker.datatype.number(),
                estimate_total_rows: faker.datatype.number(),
              },
              error_msg: faker.lorem.slug(1),
            })),
            ignore_checking_items: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => 'version'),
          })),
        }),
      ],
      [
        ctx.status(400),
        ctx.json({
          error_msg: faker.lorem.slug(1),
          error_code: faker.datatype.number(),
        }),
      ],
    ]

    return res(...resultArray[gen.next().value % resultArray.length])
  }),
  rest.get(`${baseURL}/api/v1/tasks/:taskName`, (req, res, ctx) => {
    const resultArray = [
      [
        ctx.status(200),
        ctx.json({
          name: 'task-1',
          task_mode: 'all',
          shard_mode: faker.random.arrayElement(['pessimistic', 'optimistic']),
          meta_schema: 'dm-meta',
          enhance_online_schema_change: true,
          on_duplicate: faker.random.arrayElement([
            'replace',
            'error',
            'ignore',
          ]),
          target_config: {
            host: '127.0.0.1',
            port: 3306,
            user: 'root',
            password: '123456',
            security: {
              ssl_ca_content: faker.lorem.slug(1),
              ssl_cert_content: faker.lorem.slug(1),
              ssl_key_content: faker.lorem.slug(1),
              cert_allowed_cn: [
                ...new Array(
                  faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                ).keys(),
              ].map(_ => faker.lorem.slug(1)),
            },
          },
          binlog_filter_rule: [...new Array(5).keys()]
            .map(_ => ({
              [faker.lorem.word()]: {
                ignore_event: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => 'all dml'),
                ignore_sql: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => '^Drop'),
              },
            }))
            .reduce((acc, next) => Object.assign(acc, next), {}),
          table_migrate_rule: [
            ...new Array(
              faker.datatype.number({ max: MAX_ARRAY_LENGTH })
            ).keys(),
          ].map(_ => ({
            source: {
              source_name: 'source-name',
              schema: 'db-*',
              table: 'tb-*',
            },
            target: {
              schema: 'db1',
              table: 'tb1',
            },
            binlog_filter_rule: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => 'rule-1'),
          })),
          source_config: {
            full_migrate_conf: {
              export_threads: faker.datatype.number(),
              import_threads: faker.datatype.number(),
              data_dir: './exported_data',
              consistency: 'auto',
            },
            incr_migrate_conf: {
              repl_threads: faker.datatype.number(),
              repl_batch: faker.datatype.number(),
            },
            source_conf: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => ({
              source_name: 'mysql-replica-01',
              binlog_name: 'binlog.000001',
              binlog_pos: 4,
              binlog_gtid:
                '03fc0263-28c7-11e7-a653-6c0b84d59f30:1-7041423,05474d3c-28c7-11e7-8352-203db246dd3d:1-170',
            })),
          },
          status_list: [
            ...new Array(
              faker.datatype.number({ max: MAX_ARRAY_LENGTH })
            ).keys(),
          ].map(_ => ({
            name: faker.name.findName(),
            source_name: faker.name.findName(),
            worker_name: faker.name.findName(),
            stage: faker.random.arrayElement([
              'Stopped',
              'Running',
              'Finished',
            ]),
            unit: 'sync',
            unresolved_ddl_lock_id: faker.lorem.slug(1),
            load_status: {
              finished_bytes: faker.datatype.number(),
              total_bytes: faker.datatype.number(),
              progress: faker.lorem.slug(1),
              meta_binlog: faker.lorem.slug(1),
              meta_binlog_gtid: faker.lorem.slug(1),
            },
            sync_status: {
              total_events: faker.datatype.number(),
              total_tps: faker.datatype.number(),
              recent_tps: faker.datatype.number(),
              master_binlog: faker.lorem.slug(1),
              master_binlog_gtid: faker.lorem.slug(1),
              syncer_binlog: faker.lorem.slug(1),
              syncer_binlog_gtid: faker.lorem.slug(1),
              blocking_ddls: [
                ...new Array(
                  faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                ).keys(),
              ].map(_ => faker.lorem.slug(1)),
              unresolved_groups: [
                ...new Array(
                  faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                ).keys(),
              ].map(_ => ({
                target: faker.lorem.slug(1),
                ddl_list: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => faker.lorem.slug(1)),
                first_location: faker.lorem.slug(1),
                synced: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => faker.lorem.slug(1)),
                unsynced: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => faker.lorem.slug(1)),
              })),
              synced: faker.datatype.boolean(),
              binlog_type: faker.lorem.slug(1),
              seconds_behind_master: faker.datatype.number(),
            },
            dump_status: {
              total_tables: faker.datatype.number(),
              completed_tables: faker.datatype.number(),
              finished_bytes: faker.datatype.number(),
              finished_rows: faker.datatype.number(),
              estimate_total_rows: faker.datatype.number(),
            },
            error_msg: faker.lorem.slug(1),
          })),
          ignore_checking_items: [
            ...new Array(
              faker.datatype.number({ max: MAX_ARRAY_LENGTH })
            ).keys(),
          ].map(_ => 'version'),
        }),
      ],
      [ctx.status(404), ctx.json(null)],
    ]

    return res(...resultArray[gen.next().value % resultArray.length])
  }),
  rest.delete(`${baseURL}/api/v1/tasks/:taskName`, (req, res, ctx) => {
    const resultArray = [
      [ctx.status(204), ctx.json(null)],
      [
        ctx.status(400),
        ctx.json({
          error_msg: faker.lorem.slug(1),
          error_code: faker.datatype.number(),
        }),
      ],
    ]

    return res(...resultArray[gen.next().value % resultArray.length])
  }),
  rest.put(`${baseURL}/api/v1/tasks/:taskName`, (req, res, ctx) => {
    const resultArray = [
      [
        ctx.status(200),
        ctx.json({
          task: {
            name: 'task-1',
            task_mode: 'all',
            shard_mode: faker.random.arrayElement([
              'pessimistic',
              'optimistic',
            ]),
            meta_schema: 'dm-meta',
            enhance_online_schema_change: true,
            on_duplicate: faker.random.arrayElement([
              'replace',
              'error',
              'ignore',
            ]),
            target_config: {
              host: '127.0.0.1',
              port: 3306,
              user: 'root',
              password: '123456',
              security: {
                ssl_ca_content: faker.lorem.slug(1),
                ssl_cert_content: faker.lorem.slug(1),
                ssl_key_content: faker.lorem.slug(1),
                cert_allowed_cn: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => faker.lorem.slug(1)),
              },
            },
            binlog_filter_rule: [...new Array(5).keys()]
              .map(_ => ({
                [faker.lorem.word()]: {
                  ignore_event: [
                    ...new Array(
                      faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                    ).keys(),
                  ].map(_ => 'all dml'),
                  ignore_sql: [
                    ...new Array(
                      faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                    ).keys(),
                  ].map(_ => '^Drop'),
                },
              }))
              .reduce((acc, next) => Object.assign(acc, next), {}),
            table_migrate_rule: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => ({
              source: {
                source_name: 'source-name',
                schema: 'db-*',
                table: 'tb-*',
              },
              target: {
                schema: 'db1',
                table: 'tb1',
              },
              binlog_filter_rule: [
                ...new Array(
                  faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                ).keys(),
              ].map(_ => 'rule-1'),
            })),
            source_config: {
              full_migrate_conf: {
                export_threads: faker.datatype.number(),
                import_threads: faker.datatype.number(),
                data_dir: './exported_data',
                consistency: 'auto',
              },
              incr_migrate_conf: {
                repl_threads: faker.datatype.number(),
                repl_batch: faker.datatype.number(),
              },
              source_conf: [
                ...new Array(
                  faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                ).keys(),
              ].map(_ => ({
                source_name: 'mysql-replica-01',
                binlog_name: 'binlog.000001',
                binlog_pos: 4,
                binlog_gtid:
                  '03fc0263-28c7-11e7-a653-6c0b84d59f30:1-7041423,05474d3c-28c7-11e7-8352-203db246dd3d:1-170',
              })),
            },
            status_list: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => ({
              name: faker.name.findName(),
              source_name: faker.name.findName(),
              worker_name: faker.name.findName(),
              stage: faker.random.arrayElement([
                'Stopped',
                'Running',
                'Finished',
              ]),
              unit: 'sync',
              unresolved_ddl_lock_id: faker.lorem.slug(1),
              load_status: {
                finished_bytes: faker.datatype.number(),
                total_bytes: faker.datatype.number(),
                progress: faker.lorem.slug(1),
                meta_binlog: faker.lorem.slug(1),
                meta_binlog_gtid: faker.lorem.slug(1),
              },
              sync_status: {
                total_events: faker.datatype.number(),
                total_tps: faker.datatype.number(),
                recent_tps: faker.datatype.number(),
                master_binlog: faker.lorem.slug(1),
                master_binlog_gtid: faker.lorem.slug(1),
                syncer_binlog: faker.lorem.slug(1),
                syncer_binlog_gtid: faker.lorem.slug(1),
                blocking_ddls: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => faker.lorem.slug(1)),
                unresolved_groups: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => ({
                  target: faker.lorem.slug(1),
                  ddl_list: [
                    ...new Array(
                      faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                    ).keys(),
                  ].map(_ => faker.lorem.slug(1)),
                  first_location: faker.lorem.slug(1),
                  synced: [
                    ...new Array(
                      faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                    ).keys(),
                  ].map(_ => faker.lorem.slug(1)),
                  unsynced: [
                    ...new Array(
                      faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                    ).keys(),
                  ].map(_ => faker.lorem.slug(1)),
                })),
                synced: faker.datatype.boolean(),
                binlog_type: faker.lorem.slug(1),
                seconds_behind_master: faker.datatype.number(),
              },
              dump_status: {
                total_tables: faker.datatype.number(),
                completed_tables: faker.datatype.number(),
                finished_bytes: faker.datatype.number(),
                finished_rows: faker.datatype.number(),
                estimate_total_rows: faker.datatype.number(),
              },
              error_msg: faker.lorem.slug(1),
            })),
            ignore_checking_items: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => 'version'),
          },
          check_result: 'pre-check is passed. ',
        }),
      ],
      [
        ctx.status(400),
        ctx.json({
          error_msg: faker.lorem.slug(1),
          error_code: faker.datatype.number(),
        }),
      ],
    ]

    return res(...resultArray[gen.next().value % resultArray.length])
  }),
  rest.get(`${baseURL}/api/v1/tasks/:taskName/status`, (req, res, ctx) => {
    const resultArray = [
      [
        ctx.status(200),
        ctx.json({
          total: faker.datatype.number(),
          data: [
            ...new Array(
              faker.datatype.number({ max: MAX_ARRAY_LENGTH })
            ).keys(),
          ].map(_ => ({
            name: faker.name.findName(),
            source_name: faker.name.findName(),
            worker_name: faker.name.findName(),
            stage: faker.random.arrayElement([
              'Stopped',
              'Running',
              'Finished',
            ]),
            unit: 'sync',
            unresolved_ddl_lock_id: faker.lorem.slug(1),
            load_status: {
              finished_bytes: faker.datatype.number(),
              total_bytes: faker.datatype.number(),
              progress: faker.lorem.slug(1),
              meta_binlog: faker.lorem.slug(1),
              meta_binlog_gtid: faker.lorem.slug(1),
            },
            sync_status: {
              total_events: faker.datatype.number(),
              total_tps: faker.datatype.number(),
              recent_tps: faker.datatype.number(),
              master_binlog: faker.lorem.slug(1),
              master_binlog_gtid: faker.lorem.slug(1),
              syncer_binlog: faker.lorem.slug(1),
              syncer_binlog_gtid: faker.lorem.slug(1),
              blocking_ddls: [
                ...new Array(
                  faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                ).keys(),
              ].map(_ => faker.lorem.slug(1)),
              unresolved_groups: [
                ...new Array(
                  faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                ).keys(),
              ].map(_ => ({
                target: faker.lorem.slug(1),
                ddl_list: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => faker.lorem.slug(1)),
                first_location: faker.lorem.slug(1),
                synced: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => faker.lorem.slug(1)),
                unsynced: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => faker.lorem.slug(1)),
              })),
              synced: faker.datatype.boolean(),
              binlog_type: faker.lorem.slug(1),
              seconds_behind_master: faker.datatype.number(),
            },
            dump_status: {
              total_tables: faker.datatype.number(),
              completed_tables: faker.datatype.number(),
              finished_bytes: faker.datatype.number(),
              finished_rows: faker.datatype.number(),
              estimate_total_rows: faker.datatype.number(),
            },
            error_msg: faker.lorem.slug(1),
          })),
        }),
      ],
      [
        ctx.status(400),
        ctx.json({
          error_msg: faker.lorem.slug(1),
          error_code: faker.datatype.number(),
        }),
      ],
    ]

    return res(...resultArray[gen.next().value % resultArray.length])
  }),
  rest.post(`${baseURL}/api/v1/tasks/:taskName/start`, (req, res, ctx) => {
    const resultArray = [
      [ctx.status(200), ctx.json(null)],
      // [
      //   ctx.status(400),
      //   ctx.json({
      //     error_msg: faker.lorem.slug(1),
      //     error_code: faker.datatype.number(),
      //   }),
      // ],
    ]

    return res(...resultArray[gen.next().value % resultArray.length])
  }),
  rest.post(`${baseURL}/api/v1/tasks/:taskName/stop`, (req, res, ctx) => {
    const resultArray = [
      [ctx.status(200), ctx.json(null)],
      [
        ctx.status(400),
        ctx.json({
          error_msg: faker.lorem.slug(1),
          error_code: faker.datatype.number(),
        }),
      ],
    ]

    return res(...resultArray[gen.next().value % resultArray.length])
  }),
  rest.get(
    `${baseURL}/api/v1/tasks/:taskName/sources/:sourceName/migrate_targets`,
    (req, res, ctx) => {
      const resultArray = [
        [
          ctx.status(200),
          ctx.json({
            total: faker.datatype.number(),
            data: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => ({
              source_schema: 'db1',
              source_table: 'tb1',
              target_schema: 'db1',
              target_table: 'tb1',
            })),
          }),
        ],
        [
          ctx.status(400),
          ctx.json({
            error_msg: faker.lorem.slug(1),
            error_code: faker.datatype.number(),
          }),
        ],
      ]

      return res(...resultArray[gen.next().value % resultArray.length])
    }
  ),
  rest.get(
    `${baseURL}/api/v1/tasks/:taskName/sources/:sourceName/schemas`,
    (req, res, ctx) => {
      const resultArray = [
        [
          ctx.status(200),
          ctx.json(
            [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => 'db1')
          ),
        ],
        [
          ctx.status(400),
          ctx.json({
            error_msg: faker.lorem.slug(1),
            error_code: faker.datatype.number(),
          }),
        ],
      ]

      return res(...resultArray[gen.next().value % resultArray.length])
    }
  ),
  rest.get(
    `${baseURL}/api/v1/tasks/:taskName/sources/:sourceName/schemas/:schemaName`,
    (req, res, ctx) => {
      const resultArray = [
        [
          ctx.status(200),
          ctx.json(
            [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => 'table1')
          ),
        ],
        [
          ctx.status(400),
          ctx.json({
            error_msg: faker.lorem.slug(1),
            error_code: faker.datatype.number(),
          }),
        ],
      ]

      return res(...resultArray[gen.next().value % resultArray.length])
    }
  ),
  rest.get(
    `${baseURL}/api/v1/tasks/:taskName/sources/:sourceName/schemas/:schemaName/:tableName`,
    (req, res, ctx) => {
      const resultArray = [
        [
          ctx.status(200),
          ctx.json({
            schema_name: 'db1',
            table_name: 'table1',
            schema_create_sql:
              'CREATE TABLE `t1` (`id` int(11) NOT NULL AUTO_INCREMENT,PRIMARY KEY (`id`) /*T![clustered_index] CLUSTERED */) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin',
          }),
        ],
        [
          ctx.status(400),
          ctx.json({
            error_msg: faker.lorem.slug(1),
            error_code: faker.datatype.number(),
          }),
        ],
      ]

      return res(...resultArray[gen.next().value % resultArray.length])
    }
  ),
  rest.put(
    `${baseURL}/api/v1/tasks/:taskName/sources/:sourceName/schemas/:schemaName/:tableName`,
    (req, res, ctx) => {
      const resultArray = [
        [ctx.status(200), ctx.json(null)],
        [
          ctx.status(400),
          ctx.json({
            error_msg: faker.lorem.slug(1),
            error_code: faker.datatype.number(),
          }),
        ],
      ]

      return res(...resultArray[gen.next().value % resultArray.length])
    }
  ),
  rest.delete(
    `${baseURL}/api/v1/tasks/:taskName/sources/:sourceName/schemas/:schemaName/:tableName`,
    (req, res, ctx) => {
      const resultArray = [
        [ctx.status(204), ctx.json(null)],
        [
          ctx.status(400),
          ctx.json({
            error_msg: faker.lorem.slug(1),
            error_code: faker.datatype.number(),
          }),
        ],
      ]

      return res(...resultArray[gen.next().value % resultArray.length])
    }
  ),
  rest.post(`${baseURL}/api/v1/tasks/converters`, (req, res, ctx) => {
    const resultArray = [
      [
        ctx.status(201),
        ctx.json({
          task: {
            name: 'task-1',
            task_mode: 'all',
            shard_mode: faker.random.arrayElement([
              'pessimistic',
              'optimistic',
            ]),
            meta_schema: 'dm-meta',
            enhance_online_schema_change: true,
            on_duplicate: faker.random.arrayElement([
              'replace',
              'error',
              'ignore',
            ]),
            target_config: {
              host: '127.0.0.1',
              port: 3306,
              user: 'root',
              password: '123456',
              security: {
                ssl_ca_content: faker.lorem.slug(1),
                ssl_cert_content: faker.lorem.slug(1),
                ssl_key_content: faker.lorem.slug(1),
                cert_allowed_cn: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => faker.lorem.slug(1)),
              },
            },
            binlog_filter_rule: [...new Array(5).keys()]
              .map(_ => ({
                [faker.lorem.word()]: {
                  ignore_event: [
                    ...new Array(
                      faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                    ).keys(),
                  ].map(_ => 'all dml'),
                  ignore_sql: [
                    ...new Array(
                      faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                    ).keys(),
                  ].map(_ => '^Drop'),
                },
              }))
              .reduce((acc, next) => Object.assign(acc, next), {}),
            table_migrate_rule: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => ({
              source: {
                source_name: 'source-name',
                schema: 'db-*',
                table: 'tb-*',
              },
              target: {
                schema: 'db1',
                table: 'tb1',
              },
              binlog_filter_rule: [
                ...new Array(
                  faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                ).keys(),
              ].map(_ => 'rule-1'),
            })),
            source_config: {
              full_migrate_conf: {
                export_threads: faker.datatype.number(),
                import_threads: faker.datatype.number(),
                data_dir: './exported_data',
                consistency: 'auto',
              },
              incr_migrate_conf: {
                repl_threads: faker.datatype.number(),
                repl_batch: faker.datatype.number(),
              },
              source_conf: [
                ...new Array(
                  faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                ).keys(),
              ].map(_ => ({
                source_name: 'mysql-replica-01',
                binlog_name: 'binlog.000001',
                binlog_pos: 4,
                binlog_gtid:
                  '03fc0263-28c7-11e7-a653-6c0b84d59f30:1-7041423,05474d3c-28c7-11e7-8352-203db246dd3d:1-170',
              })),
            },
            status_list: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => ({
              name: faker.name.findName(),
              source_name: faker.name.findName(),
              worker_name: faker.name.findName(),
              stage: faker.random.arrayElement([
                'Stopped',
                'Running',
                'Finished',
              ]),
              unit: 'sync',
              unresolved_ddl_lock_id: faker.lorem.slug(1),
              load_status: {
                finished_bytes: faker.datatype.number(),
                total_bytes: faker.datatype.number(),
                progress: faker.lorem.slug(1),
                meta_binlog: faker.lorem.slug(1),
                meta_binlog_gtid: faker.lorem.slug(1),
              },
              sync_status: {
                total_events: faker.datatype.number(),
                total_tps: faker.datatype.number(),
                recent_tps: faker.datatype.number(),
                master_binlog: faker.lorem.slug(1),
                master_binlog_gtid: faker.lorem.slug(1),
                syncer_binlog: faker.lorem.slug(1),
                syncer_binlog_gtid: faker.lorem.slug(1),
                blocking_ddls: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => faker.lorem.slug(1)),
                unresolved_groups: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => ({
                  target: faker.lorem.slug(1),
                  ddl_list: [
                    ...new Array(
                      faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                    ).keys(),
                  ].map(_ => faker.lorem.slug(1)),
                  first_location: faker.lorem.slug(1),
                  synced: [
                    ...new Array(
                      faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                    ).keys(),
                  ].map(_ => faker.lorem.slug(1)),
                  unsynced: [
                    ...new Array(
                      faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                    ).keys(),
                  ].map(_ => faker.lorem.slug(1)),
                })),
                synced: faker.datatype.boolean(),
                binlog_type: faker.lorem.slug(1),
                seconds_behind_master: faker.datatype.number(),
              },
              dump_status: {
                total_tables: faker.datatype.number(),
                completed_tables: faker.datatype.number(),
                finished_bytes: faker.datatype.number(),
                finished_rows: faker.datatype.number(),
                estimate_total_rows: faker.datatype.number(),
              },
              error_msg: faker.lorem.slug(1),
            })),
            ignore_checking_items: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => 'version'),
          },
          task_config_file: faker.lorem.slug(1),
        }),
      ],
      [
        ctx.status(400),
        ctx.json({
          error_msg: faker.lorem.slug(1),
          error_code: faker.datatype.number(),
        }),
      ],
    ]

    return res(...resultArray[gen.next().value % resultArray.length])
  }),
  rest.post(`${baseURL}/api/v1/tasks/templates`, (req, res, ctx) => {
    const resultArray = [
      [
        ctx.status(201),
        ctx.json({
          name: 'task-1',
          task_mode: 'all',
          shard_mode: faker.random.arrayElement(['pessimistic', 'optimistic']),
          meta_schema: 'dm-meta',
          enhance_online_schema_change: true,
          on_duplicate: faker.random.arrayElement([
            'replace',
            'error',
            'ignore',
          ]),
          target_config: {
            host: '127.0.0.1',
            port: 3306,
            user: 'root',
            password: '123456',
            security: {
              ssl_ca_content: faker.lorem.slug(1),
              ssl_cert_content: faker.lorem.slug(1),
              ssl_key_content: faker.lorem.slug(1),
              cert_allowed_cn: [
                ...new Array(
                  faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                ).keys(),
              ].map(_ => faker.lorem.slug(1)),
            },
          },
          binlog_filter_rule: [...new Array(5).keys()]
            .map(_ => ({
              [faker.lorem.word()]: {
                ignore_event: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => 'all dml'),
                ignore_sql: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => '^Drop'),
              },
            }))
            .reduce((acc, next) => Object.assign(acc, next), {}),
          table_migrate_rule: [
            ...new Array(
              faker.datatype.number({ max: MAX_ARRAY_LENGTH })
            ).keys(),
          ].map(_ => ({
            source: {
              source_name: 'source-name',
              schema: 'db-*',
              table: 'tb-*',
            },
            target: {
              schema: 'db1',
              table: 'tb1',
            },
            binlog_filter_rule: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => 'rule-1'),
          })),
          source_config: {
            full_migrate_conf: {
              export_threads: faker.datatype.number(),
              import_threads: faker.datatype.number(),
              data_dir: './exported_data',
              consistency: 'auto',
            },
            incr_migrate_conf: {
              repl_threads: faker.datatype.number(),
              repl_batch: faker.datatype.number(),
            },
            source_conf: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => ({
              source_name: 'mysql-replica-01',
              binlog_name: 'binlog.000001',
              binlog_pos: 4,
              binlog_gtid:
                '03fc0263-28c7-11e7-a653-6c0b84d59f30:1-7041423,05474d3c-28c7-11e7-8352-203db246dd3d:1-170',
            })),
          },
          status_list: [
            ...new Array(
              faker.datatype.number({ max: MAX_ARRAY_LENGTH })
            ).keys(),
          ].map(_ => ({
            name: faker.name.findName(),
            source_name: faker.name.findName(),
            worker_name: faker.name.findName(),
            stage: faker.random.arrayElement([
              'Stopped',
              'Running',
              'Finished',
            ]),
            unit: 'sync',
            unresolved_ddl_lock_id: faker.lorem.slug(1),
            load_status: {
              finished_bytes: faker.datatype.number(),
              total_bytes: faker.datatype.number(),
              progress: faker.lorem.slug(1),
              meta_binlog: faker.lorem.slug(1),
              meta_binlog_gtid: faker.lorem.slug(1),
            },
            sync_status: {
              total_events: faker.datatype.number(),
              total_tps: faker.datatype.number(),
              recent_tps: faker.datatype.number(),
              master_binlog: faker.lorem.slug(1),
              master_binlog_gtid: faker.lorem.slug(1),
              syncer_binlog: faker.lorem.slug(1),
              syncer_binlog_gtid: faker.lorem.slug(1),
              blocking_ddls: [
                ...new Array(
                  faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                ).keys(),
              ].map(_ => faker.lorem.slug(1)),
              unresolved_groups: [
                ...new Array(
                  faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                ).keys(),
              ].map(_ => ({
                target: faker.lorem.slug(1),
                ddl_list: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => faker.lorem.slug(1)),
                first_location: faker.lorem.slug(1),
                synced: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => faker.lorem.slug(1)),
                unsynced: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => faker.lorem.slug(1)),
              })),
              synced: faker.datatype.boolean(),
              binlog_type: faker.lorem.slug(1),
              seconds_behind_master: faker.datatype.number(),
            },
            dump_status: {
              total_tables: faker.datatype.number(),
              completed_tables: faker.datatype.number(),
              finished_bytes: faker.datatype.number(),
              finished_rows: faker.datatype.number(),
              estimate_total_rows: faker.datatype.number(),
            },
            error_msg: faker.lorem.slug(1),
          })),
          ignore_checking_items: [
            ...new Array(
              faker.datatype.number({ max: MAX_ARRAY_LENGTH })
            ).keys(),
          ].map(_ => 'version'),
        }),
      ],
      [
        ctx.status(400),
        ctx.json({
          error_msg: faker.lorem.slug(1),
          error_code: faker.datatype.number(),
        }),
      ],
    ]

    return res(...resultArray[gen.next().value % resultArray.length])
  }),
  rest.get(`${baseURL}/api/v1/tasks/templates`, (req, res, ctx) => {
    const resultArray = [
      [
        ctx.status(200),
        ctx.json({
          total: faker.datatype.number(),
          data: [
            ...new Array(
              faker.datatype.number({ max: MAX_ARRAY_LENGTH })
            ).keys(),
          ].map(_ => ({
            name: 'task-1',
            task_mode: 'all',
            shard_mode: faker.random.arrayElement([
              'pessimistic',
              'optimistic',
            ]),
            meta_schema: 'dm-meta',
            enhance_online_schema_change: true,
            on_duplicate: faker.random.arrayElement([
              'replace',
              'error',
              'ignore',
            ]),
            target_config: {
              host: '127.0.0.1',
              port: 3306,
              user: 'root',
              password: '123456',
              security: {
                ssl_ca_content: faker.lorem.slug(1),
                ssl_cert_content: faker.lorem.slug(1),
                ssl_key_content: faker.lorem.slug(1),
                cert_allowed_cn: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => faker.lorem.slug(1)),
              },
            },
            binlog_filter_rule: [...new Array(5).keys()]
              .map(_ => ({
                [faker.lorem.word()]: {
                  ignore_event: [
                    ...new Array(
                      faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                    ).keys(),
                  ].map(_ => 'all dml'),
                  ignore_sql: [
                    ...new Array(
                      faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                    ).keys(),
                  ].map(_ => '^Drop'),
                },
              }))
              .reduce((acc, next) => Object.assign(acc, next), {}),
            table_migrate_rule: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => ({
              source: {
                source_name: 'source-name',
                schema: 'db-*',
                table: 'tb-*',
              },
              target: {
                schema: 'db1',
                table: 'tb1',
              },
              binlog_filter_rule: [
                ...new Array(
                  faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                ).keys(),
              ].map(_ => 'rule-1'),
            })),
            source_config: {
              full_migrate_conf: {
                export_threads: faker.datatype.number(),
                import_threads: faker.datatype.number(),
                data_dir: './exported_data',
                consistency: 'auto',
              },
              incr_migrate_conf: {
                repl_threads: faker.datatype.number(),
                repl_batch: faker.datatype.number(),
              },
              source_conf: [
                ...new Array(
                  faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                ).keys(),
              ].map(_ => ({
                source_name: 'mysql-replica-01',
                binlog_name: 'binlog.000001',
                binlog_pos: 4,
                binlog_gtid:
                  '03fc0263-28c7-11e7-a653-6c0b84d59f30:1-7041423,05474d3c-28c7-11e7-8352-203db246dd3d:1-170',
              })),
            },
            status_list: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => ({
              name: faker.name.findName(),
              source_name: faker.name.findName(),
              worker_name: faker.name.findName(),
              stage: faker.random.arrayElement([
                'Stopped',
                'Running',
                'Finished',
              ]),
              unit: 'sync',
              unresolved_ddl_lock_id: faker.lorem.slug(1),
              load_status: {
                finished_bytes: faker.datatype.number(),
                total_bytes: faker.datatype.number(),
                progress: faker.lorem.slug(1),
                meta_binlog: faker.lorem.slug(1),
                meta_binlog_gtid: faker.lorem.slug(1),
              },
              sync_status: {
                total_events: faker.datatype.number(),
                total_tps: faker.datatype.number(),
                recent_tps: faker.datatype.number(),
                master_binlog: faker.lorem.slug(1),
                master_binlog_gtid: faker.lorem.slug(1),
                syncer_binlog: faker.lorem.slug(1),
                syncer_binlog_gtid: faker.lorem.slug(1),
                blocking_ddls: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => faker.lorem.slug(1)),
                unresolved_groups: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => ({
                  target: faker.lorem.slug(1),
                  ddl_list: [
                    ...new Array(
                      faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                    ).keys(),
                  ].map(_ => faker.lorem.slug(1)),
                  first_location: faker.lorem.slug(1),
                  synced: [
                    ...new Array(
                      faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                    ).keys(),
                  ].map(_ => faker.lorem.slug(1)),
                  unsynced: [
                    ...new Array(
                      faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                    ).keys(),
                  ].map(_ => faker.lorem.slug(1)),
                })),
                synced: faker.datatype.boolean(),
                binlog_type: faker.lorem.slug(1),
                seconds_behind_master: faker.datatype.number(),
              },
              dump_status: {
                total_tables: faker.datatype.number(),
                completed_tables: faker.datatype.number(),
                finished_bytes: faker.datatype.number(),
                finished_rows: faker.datatype.number(),
                estimate_total_rows: faker.datatype.number(),
              },
              error_msg: faker.lorem.slug(1),
            })),
            ignore_checking_items: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => 'version'),
          })),
        }),
      ],
      [
        ctx.status(400),
        ctx.json({
          error_msg: faker.lorem.slug(1),
          error_code: faker.datatype.number(),
        }),
      ],
    ]

    return res(...resultArray[gen.next().value % resultArray.length])
  }),
  rest.post(`${baseURL}/api/v1/tasks/templates/import`, (req, res, ctx) => {
    const resultArray = [
      [
        ctx.status(202),
        ctx.json({
          success_task_list: [
            ...new Array(
              faker.datatype.number({ max: MAX_ARRAY_LENGTH })
            ).keys(),
          ].map(_ => faker.lorem.slug(1)),
          failed_task_list: [
            ...new Array(
              faker.datatype.number({ max: MAX_ARRAY_LENGTH })
            ).keys(),
          ].map(_ => ({
            task_name: faker.name.findName(),
            error_msg: faker.lorem.slug(1),
          })),
        }),
      ],
      [
        ctx.status(400),
        ctx.json({
          error_msg: faker.lorem.slug(1),
          error_code: faker.datatype.number(),
        }),
      ],
    ]

    return res(...resultArray[gen.next().value % resultArray.length])
  }),
  rest.get(`${baseURL}/api/v1/tasks/templates/:taskName`, (req, res, ctx) => {
    const resultArray = [
      [
        ctx.status(200),
        ctx.json({
          name: 'task-1',
          task_mode: 'all',
          shard_mode: faker.random.arrayElement(['pessimistic', 'optimistic']),
          meta_schema: 'dm-meta',
          enhance_online_schema_change: true,
          on_duplicate: faker.random.arrayElement([
            'replace',
            'error',
            'ignore',
          ]),
          target_config: {
            host: '127.0.0.1',
            port: 3306,
            user: 'root',
            password: '123456',
            security: {
              ssl_ca_content: faker.lorem.slug(1),
              ssl_cert_content: faker.lorem.slug(1),
              ssl_key_content: faker.lorem.slug(1),
              cert_allowed_cn: [
                ...new Array(
                  faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                ).keys(),
              ].map(_ => faker.lorem.slug(1)),
            },
          },
          binlog_filter_rule: [...new Array(5).keys()]
            .map(_ => ({
              [faker.lorem.word()]: {
                ignore_event: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => 'all dml'),
                ignore_sql: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => '^Drop'),
              },
            }))
            .reduce((acc, next) => Object.assign(acc, next), {}),
          table_migrate_rule: [
            ...new Array(
              faker.datatype.number({ max: MAX_ARRAY_LENGTH })
            ).keys(),
          ].map(_ => ({
            source: {
              source_name: 'source-name',
              schema: 'db-*',
              table: 'tb-*',
            },
            target: {
              schema: 'db1',
              table: 'tb1',
            },
            binlog_filter_rule: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => 'rule-1'),
          })),
          source_config: {
            full_migrate_conf: {
              export_threads: faker.datatype.number(),
              import_threads: faker.datatype.number(),
              data_dir: './exported_data',
              consistency: 'auto',
            },
            incr_migrate_conf: {
              repl_threads: faker.datatype.number(),
              repl_batch: faker.datatype.number(),
            },
            source_conf: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => ({
              source_name: 'mysql-replica-01',
              binlog_name: 'binlog.000001',
              binlog_pos: 4,
              binlog_gtid:
                '03fc0263-28c7-11e7-a653-6c0b84d59f30:1-7041423,05474d3c-28c7-11e7-8352-203db246dd3d:1-170',
            })),
          },
          status_list: [
            ...new Array(
              faker.datatype.number({ max: MAX_ARRAY_LENGTH })
            ).keys(),
          ].map(_ => ({
            name: faker.name.findName(),
            source_name: faker.name.findName(),
            worker_name: faker.name.findName(),
            stage: faker.random.arrayElement([
              'Stopped',
              'Running',
              'Finished',
            ]),
            unit: 'sync',
            unresolved_ddl_lock_id: faker.lorem.slug(1),
            load_status: {
              finished_bytes: faker.datatype.number(),
              total_bytes: faker.datatype.number(),
              progress: faker.lorem.slug(1),
              meta_binlog: faker.lorem.slug(1),
              meta_binlog_gtid: faker.lorem.slug(1),
            },
            sync_status: {
              total_events: faker.datatype.number(),
              total_tps: faker.datatype.number(),
              recent_tps: faker.datatype.number(),
              master_binlog: faker.lorem.slug(1),
              master_binlog_gtid: faker.lorem.slug(1),
              syncer_binlog: faker.lorem.slug(1),
              syncer_binlog_gtid: faker.lorem.slug(1),
              blocking_ddls: [
                ...new Array(
                  faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                ).keys(),
              ].map(_ => faker.lorem.slug(1)),
              unresolved_groups: [
                ...new Array(
                  faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                ).keys(),
              ].map(_ => ({
                target: faker.lorem.slug(1),
                ddl_list: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => faker.lorem.slug(1)),
                first_location: faker.lorem.slug(1),
                synced: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => faker.lorem.slug(1)),
                unsynced: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => faker.lorem.slug(1)),
              })),
              synced: faker.datatype.boolean(),
              binlog_type: faker.lorem.slug(1),
              seconds_behind_master: faker.datatype.number(),
            },
            dump_status: {
              total_tables: faker.datatype.number(),
              completed_tables: faker.datatype.number(),
              finished_bytes: faker.datatype.number(),
              finished_rows: faker.datatype.number(),
              estimate_total_rows: faker.datatype.number(),
            },
            error_msg: faker.lorem.slug(1),
          })),
          ignore_checking_items: [
            ...new Array(
              faker.datatype.number({ max: MAX_ARRAY_LENGTH })
            ).keys(),
          ].map(_ => 'version'),
        }),
      ],
      [
        ctx.status(400),
        ctx.json({
          error_msg: faker.lorem.slug(1),
          error_code: faker.datatype.number(),
        }),
      ],
    ]

    return res(...resultArray[gen.next().value % resultArray.length])
  }),
  rest.put(`${baseURL}/api/v1/tasks/templates/:taskName`, (req, res, ctx) => {
    const resultArray = [
      [
        ctx.status(200),
        ctx.json({
          name: 'task-1',
          task_mode: 'all',
          shard_mode: faker.random.arrayElement(['pessimistic', 'optimistic']),
          meta_schema: 'dm-meta',
          enhance_online_schema_change: true,
          on_duplicate: faker.random.arrayElement([
            'replace',
            'error',
            'ignore',
          ]),
          target_config: {
            host: '127.0.0.1',
            port: 3306,
            user: 'root',
            password: '123456',
            security: {
              ssl_ca_content: faker.lorem.slug(1),
              ssl_cert_content: faker.lorem.slug(1),
              ssl_key_content: faker.lorem.slug(1),
              cert_allowed_cn: [
                ...new Array(
                  faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                ).keys(),
              ].map(_ => faker.lorem.slug(1)),
            },
          },
          binlog_filter_rule: [...new Array(5).keys()]
            .map(_ => ({
              [faker.lorem.word()]: {
                ignore_event: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => 'all dml'),
                ignore_sql: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => '^Drop'),
              },
            }))
            .reduce((acc, next) => Object.assign(acc, next), {}),
          table_migrate_rule: [
            ...new Array(
              faker.datatype.number({ max: MAX_ARRAY_LENGTH })
            ).keys(),
          ].map(_ => ({
            source: {
              source_name: 'source-name',
              schema: 'db-*',
              table: 'tb-*',
            },
            target: {
              schema: 'db1',
              table: 'tb1',
            },
            binlog_filter_rule: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => 'rule-1'),
          })),
          source_config: {
            full_migrate_conf: {
              export_threads: faker.datatype.number(),
              import_threads: faker.datatype.number(),
              data_dir: './exported_data',
              consistency: 'auto',
            },
            incr_migrate_conf: {
              repl_threads: faker.datatype.number(),
              repl_batch: faker.datatype.number(),
            },
            source_conf: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => ({
              source_name: 'mysql-replica-01',
              binlog_name: 'binlog.000001',
              binlog_pos: 4,
              binlog_gtid:
                '03fc0263-28c7-11e7-a653-6c0b84d59f30:1-7041423,05474d3c-28c7-11e7-8352-203db246dd3d:1-170',
            })),
          },
          status_list: [
            ...new Array(
              faker.datatype.number({ max: MAX_ARRAY_LENGTH })
            ).keys(),
          ].map(_ => ({
            name: faker.name.findName(),
            source_name: faker.name.findName(),
            worker_name: faker.name.findName(),
            stage: faker.random.arrayElement([
              'Stopped',
              'Running',
              'Finished',
            ]),
            unit: 'sync',
            unresolved_ddl_lock_id: faker.lorem.slug(1),
            load_status: {
              finished_bytes: faker.datatype.number(),
              total_bytes: faker.datatype.number(),
              progress: faker.lorem.slug(1),
              meta_binlog: faker.lorem.slug(1),
              meta_binlog_gtid: faker.lorem.slug(1),
            },
            sync_status: {
              total_events: faker.datatype.number(),
              total_tps: faker.datatype.number(),
              recent_tps: faker.datatype.number(),
              master_binlog: faker.lorem.slug(1),
              master_binlog_gtid: faker.lorem.slug(1),
              syncer_binlog: faker.lorem.slug(1),
              syncer_binlog_gtid: faker.lorem.slug(1),
              blocking_ddls: [
                ...new Array(
                  faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                ).keys(),
              ].map(_ => faker.lorem.slug(1)),
              unresolved_groups: [
                ...new Array(
                  faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                ).keys(),
              ].map(_ => ({
                target: faker.lorem.slug(1),
                ddl_list: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => faker.lorem.slug(1)),
                first_location: faker.lorem.slug(1),
                synced: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => faker.lorem.slug(1)),
                unsynced: [
                  ...new Array(
                    faker.datatype.number({ max: MAX_ARRAY_LENGTH })
                  ).keys(),
                ].map(_ => faker.lorem.slug(1)),
              })),
              synced: faker.datatype.boolean(),
              binlog_type: faker.lorem.slug(1),
              seconds_behind_master: faker.datatype.number(),
            },
            dump_status: {
              total_tables: faker.datatype.number(),
              completed_tables: faker.datatype.number(),
              finished_bytes: faker.datatype.number(),
              finished_rows: faker.datatype.number(),
              estimate_total_rows: faker.datatype.number(),
            },
            error_msg: faker.lorem.slug(1),
          })),
          ignore_checking_items: [
            ...new Array(
              faker.datatype.number({ max: MAX_ARRAY_LENGTH })
            ).keys(),
          ].map(_ => 'version'),
        }),
      ],
      [
        ctx.status(400),
        ctx.json({
          error_msg: faker.lorem.slug(1),
          error_code: faker.datatype.number(),
        }),
      ],
    ]

    return res(...resultArray[gen.next().value % resultArray.length])
  }),
  rest.delete(
    `${baseURL}/api/v1/tasks/templates/:taskName`,
    (req, res, ctx) => {
      const resultArray = [
        [ctx.status(204), ctx.json(null)],
        [
          ctx.status(400),
          ctx.json({
            error_msg: faker.lorem.slug(1),
            error_code: faker.datatype.number(),
          }),
        ],
      ]

      return res(...resultArray[gen.next().value % resultArray.length])
    }
  ),
  rest.get(`${baseURL}/api/v1/cluster/info`, (req, res, ctx) => {
    const resultArray = [
      [
        ctx.status(200),
        ctx.json({
          cluster_id: faker.datatype.number(),
          topology: {
            master_topology_list: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => ({
              name: 'master',
              host: '127.0.0.1',
              port: 8261,
            })),
            worker_topology_list: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => ({
              name: 'worker1',
              host: '127.0.0.1',
              port: 8261,
            })),
            grafana_topology: {
              host: '127.0.0.1',
              port: 3000,
            },
            prometheus_topology: {
              host: '127.0.0.1',
              port: 9090,
            },
            alert_manager_topology: {
              host: '127.0.0.1',
              port: 9093,
            },
          },
        }),
      ],
    ]

    return res(...resultArray[gen.next().value % resultArray.length])
  }),
  rest.put(`${baseURL}/api/v1/cluster/info`, (req, res, ctx) => {
    const resultArray = [
      [
        ctx.status(200),
        ctx.json({
          cluster_id: faker.datatype.number(),
          topology: {
            master_topology_list: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => ({
              name: 'master',
              host: '127.0.0.1',
              port: 8261,
            })),
            worker_topology_list: [
              ...new Array(
                faker.datatype.number({ max: MAX_ARRAY_LENGTH })
              ).keys(),
            ].map(_ => ({
              name: 'worker1',
              host: '127.0.0.1',
              port: 8261,
            })),
            grafana_topology: {
              host: '127.0.0.1',
              port: 3000,
            },
            prometheus_topology: {
              host: '127.0.0.1',
              port: 9090,
            },
            alert_manager_topology: {
              host: '127.0.0.1',
              port: 9093,
            },
          },
        }),
      ],
    ]

    return res(...resultArray[gen.next().value % resultArray.length])
  }),
  rest.get(`${baseURL}/api/v1/cluster/masters`, (req, res, ctx) => {
    const resultArray = [
      [
        ctx.status(200),
        ctx.json({
          total: faker.datatype.number(),
          data: [
            ...new Array(
              faker.datatype.number({ max: MAX_ARRAY_LENGTH })
            ).keys(),
          ].map(_ => ({
            name: 'master1',
            alive: true,
            leader: true,
            addr: '127.0.0.1:8261',
          })),
        }),
      ],
      [
        ctx.status(400),
        ctx.json({
          error_msg: faker.lorem.slug(1),
          error_code: faker.datatype.number(),
        }),
      ],
    ]

    return res(...resultArray[gen.next().value % resultArray.length])
  }),
  rest.delete(
    `${baseURL}/api/v1/cluster/masters/:masterName`,
    (req, res, ctx) => {
      const resultArray = [
        [ctx.status(204), ctx.json(null)],
        [
          ctx.status(400),
          ctx.json({
            error_msg: faker.lorem.slug(1),
            error_code: faker.datatype.number(),
          }),
        ],
      ]

      return res(...resultArray[gen.next().value % resultArray.length])
    }
  ),
  rest.get(`${baseURL}/api/v1/cluster/workers`, (req, res, ctx) => {
    const resultArray = [
      [
        ctx.status(200),
        ctx.json({
          total: faker.datatype.number(),
          data: [
            ...new Array(
              faker.datatype.number({ max: MAX_ARRAY_LENGTH })
            ).keys(),
          ].map(_ => ({
            name: 'worker1',
            addr: '127.0.0.1:8261',
            bound_stage: 'bound',
            bound_source_name: 'mysql-01',
          })),
        }),
      ],
      [
        ctx.status(400),
        ctx.json({
          error_msg: faker.lorem.slug(1),
          error_code: faker.datatype.number(),
        }),
      ],
    ]

    return res(...resultArray[gen.next().value % resultArray.length])
  }),
  rest.delete(
    `${baseURL}/api/v1/cluster/workers/:workerName`,
    (req, res, ctx) => {
      const resultArray = [
        [ctx.status(204), ctx.json(null)],
        [
          ctx.status(400),
          ctx.json({
            error_msg: faker.lorem.slug(1),
            error_code: faker.datatype.number(),
          }),
        ],
      ]

      return res(...resultArray[gen.next().value % resultArray.length])
    }
  ),
]

// This configures a Service Worker with the given request handlers.
export const startWorker = () => {
  const worker = setupWorker(...handlers)
  worker.start()
}
