{
  "add": "Add",
  "add event filter": "Add event filter",
  "add migrate rule": "Add migration rule",
  "add new source": "Add new source",
  "add source config": "Add source config",
  "address": "Address",
  "basic info": "Basics",
  "binlog": "binlog",
  "bound stage": "Bound stage",
  "cancel": "Cancel",
  "check": "Check",
  "cluster management": "Cluster",
  "confirm": "Confirm",
  "confirm to delete source": "Confirm to delete source",
  "confirm to delete task?": "Confirm to delete task?",
  "confirm to stop task?": "Confirm to stop task?",
  "consistency requirement": "Consistency",
  "create task": "Create Task",
  "create task basic info desc": "Fill in the basic information of the task, please pay attention to read the description text in each configuration.",
  "create task binlog_name tooltip": "Specifies the starting position of incremental replication. If there is an active/standby switchover in the upstream, GTID is necessary.",
  "create task data_dir tooltip": "When the task mode is \"all\" or \"full\", DM needs to first fully export the upstream data to this path on the host where the DM-worker is located. Make sure to configure it correctly and have the corresponding directory write permission and space capacity. Local absolute paths and AWS S3 are supported. When using S3, be sure to fill in the region and authentication information correctly, for example: s3://dmbucket/dump?endpoint=http://127.0.0.1:8688&access_key=s3accesskey&secret_access_key=s3secretkey&force_path_style=true&region=us-west-2.",
  "create task event filter ignore_event tooltip": "Select the predefined events that you want to ignore.",
  "create task event filter ignore_sql tooltip": "Fill in the regular expression, the matched SQL will be ignored. Multiple can be filled after carriage return.",
  "create task event filter name tooltip": "Fill in the filter name, English, numbers, \"-\", \"_\" are supported, and it can be unique within the task.",
  "create task event filters desc": "Create the event filter, which is only valid for the current task, and will be used in the next step of \"Migration Rules\" configuration.",
  "create task export_threads tooltip": "The number of threads for the dump unit to export data from the upstream database instance.",
  "create task import_threads tooltip": "The number of threads for the load unit to execute the import concurrently. The default value is 16. When there are multiple instances migrating data to TiDB at the same time, this value can be appropriately adjusted according to the load situation.",
  "create task meta db tooltip": "The name of the database used to store task checkpoint information. DM will use this name to create a database downstream, please ensure that the downstream database account provided in the next steps has sufficient permissions.",
  "create task migrate rule binlog_filter_rule tooltip": "Select the filter that needs to be matched, and the matched result will not be migrated.",
  "create task migrate rule desc": "Create the migration rules, migrating multiple upstream and tables to the downstream is supported.",
  "create task migrate rule source schema tooltip": "Select the database schema to be migrated, supports regular expressions. Or choose from the small database icons on the right.",
  "create task migrate rule source table tooltip": "Select the database tables to be migrated, supports regular expressions. Or choose from the small database icons on the right.",
  "create task migrate rule target schema tooltip": "Target database name,  keep empty if you wish to keep the original name.",
  "create task migrate rule target table tooltip": "Target table name,  keep empty if you wish to keep the original name.",
  "create task mode tooltip": "all: Automatically perform full and incremental migration. It is recommended to use when the data volume is up to terabyte, which is simple and convenient. For more than terabyte data volume , you can also consider using Lightning to complete the full migration to shorten the migration time.\n\nfull: Only perform full data migration.\n\nincremental: Only incremental data migration is performed, and the start time or binlog position needs to be specified.",
  "create task name tooltip": "Globally unique name, supports alphabets, numbers, \"_\" and \"-\", please do not use spaces and other special characters.",
  "create task repl_batch tooltip": "The number of SQL statements in a transaction batch to be replicate to the downstream database. The default value is 100, and it is recommended that it should not exceed 500 in general.",
  "create task repl_threads tooltip": "The number of concurrent threads the application has transferred to the local binlog. Adjusting this parameter does not affect the concurrency of upstream pulling logs.",
  "create task shard mode tooltip": "When there are multiple sources in a task, DM treats them as a Sharding Group to better synchronize the DDL by default. possible effects such as blocking the DDL until all sources have completed their changes.\n\n\"None\": If there is no correlation between multiple sources, this field must be set to \"None\".\n\n\"Pessimistic mode\": When an upstream sharded table executes a DDL statement, the migration of this sharded table will be suspended. After all other sharded tables execute the same DDL, the DDL will be executed in the downstream and the data migration task will restart. The advantage of this mode is that it can ensure that the data migrated to the downstream will not go wrong.\n\n\"Optimistic mode\": DM will automatically modify the DDL executed on a sharded table into a statement compatible with other sharded tables, and then migrate to the downstream. This will not block the DML migration of any sharded tables. The advantage of this mode is that it will not block data migration when processing DDL. However, improper use will cause migration interruption or even data inconsistency.",
  "create task source info desc": "Select the sources to be migrated that have been added. Replication config can adjust performance-related parameters, which generally no need to  modify. Incremental migration tasks need to specify the migration start position. Two methods are supported:\n1. Specify the binlog position for each upstream when creating a task. If there is a master-slave switch in the upstream, it must be filled GTID;\n2. When creating a task, leave the position blank, and select \"Create only\" at the end, then start the task in the task list and select the start time.",
  "create task target host tooltip": "Please fill in the connection address of the target TiDB. Domain name and IP are supported.",
  "create task target info desc": "Fill in the connection information of the downstream TiDB database. Please note:\n1. DM will create a metadata database downstream, please make sure that the account you fill in has the corresponding permissions;\n2. If using a domain name, please ensure that the host where the DM cluster is located has been configured properly with a DNS server;\n3. Password supports filling in plain text or using `dmctl encrypt` encrypted password string;\n4. Please check that the network firewall has opened the corresponding IP and port.",
  "create task target password tooltip": "Please fill in the user password of the target TiDB.",
  "create task target port tooltip": "Please fill in the connection port of the target TiDB.",
  "create task target user tooltip": "Please fill in the username of the target TiDB.",
  "current stage": "Stage",
  "dashboard loading tip": "Connecting to the monitoring component, you can change config by clicking the floating button at the bottom right corner",
  "dashboard professional": "Pro",
  "dashboard standard": "Standard",
  "dashboard view": "View",
  "data dir": "Data dir",
  "database": "Database",
  "delete": "Delete",
  "deleted": "Deleted!",
  "deleting": "Deleting...",
  "disable": "Disable",
  "disable relay": "Disable Relay Log",
  "disabled": "Disabled",
  "edit": "Edit",
  "edit config": "Edit config",
  "edit source": "Edit source",
  "edit task": "Edit task",
  "enable": "Enable",
  "enable gtid": "Enable GTID",
  "enable relay": "Enable Relay Log",
  "enabled": "Enabled",
  "event filter": "Event filter",
  "event filter ignore event": "Ignore event",
  "event filter ignore sql": "Ignore SQL",
  "event filter name": "Name",
  "event filter name is required": "Event filter name is required",
  "event filter name should be unique": "Event filter name should be unique",
  "export concurrency": "Export concurrency",
  "full migrate config": "Full replication config",
  "gtid": "GTID",
  "host": "Host",
  "host is required": "Host is required",
  "import concurrency": "Import concurrency",
  "incremental migrate config": "Incremental replication config",
  "incremental sync delay": "Incremental replication delay",
  "ip": "IP",
  "is enabled": "Enabled",
  "is leader": "Leader",
  "member list": "Members",
  "meta db": "Meta db",
  "migrate rules": "Migration rules",
  "migrate rules is required": "Migration rules are required",
  "migration": "Migration",
  "mode": "Mode",
  "name": "Name",
  "next": "Next",
  "no related task": "No related task",
  "note": "Note",
  "note-dashboard-config": "Please fill in the host and port of the deployed Grafana component.",
  "off": "Off",
  "on": "On",
  "open task by config": "Open task as plaintext config",
  "open task by config desc": "Create tasks directly by writing configuration files manually, suitable to copy from existing configuration files or for skilled users who want to define more detailed configurations",
  "open task by guide": "Open task as wizard",
  "open task by guide desc": "Create task through multi-step step-by-step guidance, suitable for new users and daily use",
  "operations": "Operations",
  "password": "Password",
  "password is required": "Password is required",
  "port": "Port",
  "port is required": "Port is required",
  "previous": "Previous",
  "refresh": "Refresh",
  "related task": "Related Task",
  "relay config (optional)": "Relay log (optional)",
  "relay log": "Relay log",
  "replication detail": "Replication Detail",
  "request success": "Request success",
  "requesting": "Requesting",
  "runtime config": "Runtime Config",
  "safe mode time duration": "Safe-Mode Duration",
  "safe mode time duration tooltip": "How long safe mode lasts after the task is started. This time is binlog time and not physical time. For a detailed description of Safe Mode and this configuration, please refer to the documentation",
  "save": "Save",
  "save and run": "Save and start",
  "search placeholder": "Search...",
  "second": "Seconds",
  "source": "Source",
  "source detail": "Source Detail",
  "source form gtid tooltip": "It is recommended to replicate by GTID(except AWS Aurora), of course the upstream needs to configure GTID first",
  "source form host tooltip": "Fill in the upstream connection address, support domain name or IP",
  "source form name tooltip": "Fill in the upstream name. Globally unique, supports alphabets, numbers, \"_\" and \"-\", does not support spaces and other special characters",
  "source form password tooltip": "Please fill in the user password",
  "source form user tooltip": "Username used to connect to the upstream database",
  "source info": "Source info",
  "source list": "Source",
  "source list desc": "Before creating a migration task, you need to create the upstream data source information. Please note:\n1. GTIDs. If there is a master-slave switchover, be sure to enable GTID in upstream MySQL and set GTID to True when creating the upstream, otherwise the data migration task will be interrupted during the master-slave switchover (except for AWS Aurora);\n2. Deactivate. If an upstream database needs to be temporarily offline, it can be deactivated, but other MySQL instances that are being replicated cannot perform DDL operations during the deactivation, otherwise the deactivated instance will not be able to synchronize normally after it is activated.\n3. relay log. When multiple migration tasks use the same upstream, it can put additional pressure on it. It is recommended to enable relay log to reduce the impact on upstream.",
  "source name": "Source name",
  "source name is required": "Source name is required",
  "source schema": "Source Database",
  "source table": "Source Table",
  "start": "Start",
  "start task with params": "Start with params",
  "start task with params desc": "The task will start according to the specified parameters, be sure to read the document about those parameters",
  "start task without params": "Start",
  "start task without params desc": "Tasks will continue to sync based on the checkpoint at the last end. If it is started for the first time, it will start at the specified location or time according to the configuration file",
  "start time on copy": "Start time",
  "start time on copy tooltip": "Synchronize all upstreams from the specified point in time, the saved location information (checkpoint) will be ignored",
  "status": "Status",
  "stop": "Stop",
  "stop_task list": "Stop",
  "submit": "Submit",
  "subtask": "Subtask",
  "sync config": "Replication config",
  "synchronous concurrency": "Sync concurrency",
  "table": "Table",
  "target": "Target",
  "target info": "Target Info",
  "target schema": "Target Database",
  "target table": "Target Table",
  "task detail": "Task Detail",
  "task list": "Task",
  "task list desc": "This module is used to manage data migration tasks. Before creating a new task, you need to add upstream database information on the sidebar-source configuration page. Please note:\n\nAutomatically support the source using the pt-osc/gh-ost online schema change tools without configuration; if you use other types of tools, or modified the default behavior of pt-osc/gh-ost yourself, please look for the online document for support;",
  "task mode": "Mode",
  "task name": "Name",
  "task name is required": "Task name is required",
  "task shard mode": "Shard mode",
  "tls config (optional)": "TLS (optional)",
  "transaction batch": "Transaction batch",
  "type": "Type",
  "user name": "User",
  "user name is required": "User name is required",
  "{{val}} and {{count}} others": "{{val}} and {{count}} in total",
  "{{val}} and {{count}} others_plural": "{{val}} and {{count}} in total"
}
