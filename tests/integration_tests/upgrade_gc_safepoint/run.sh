#!/bin/bash

set -e

CUR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
source $CUR/../_utils/test_prepare
WORK_DIR=$OUT_DIR/$TEST_NAME
CDC_BINARY=cdc.test
SINK_TYPE=$1

# Create a changefeed with given pd addr, changefeed id, sink uri and start ts.
# changefeed info fixture is generated by
# `tiup cdc:v4.0.13 cli --pd=${PD} changefeed create --sink-uri="${SINK}"
# `tiup cdc:v4.0.13 cli --pd=${PD} unsafe show-metadata`
function create_changefeed_v4013() {
	pd_addr=$1
	cfid=$2
	sink_uri=$3
	start_ts=$4
	ETCDCTL_API=3 etcdctl --endpoints=$pd_addr put \
		/tidb/cdc/changefeed/info/$cfid \
		"{
  \"sink-uri\": \"$sink_uri\",
  \"opts\": {},
  \"create-time\": \"2021-12-28T20:40:28.47898328+08:00\",
  \"start-ts\": $start_ts,
  \"target-ts\": 0,
  \"admin-job-type\": 0,
  \"sort-engine\": \"unified\",
  \"config\": {
    \"case-sensitive\": true,
    \"enable-old-value\": false,
    \"force-replicate\": false,
    \"check-gc-safe-point\": true,
    \"filter\": {
      \"rules\": [
        \"*.*\"
      ],
      \"ignore-txn-start-ts\": null,
      \"ddl-allow-list\": null
    },
    \"mounter\": {
      \"worker-num\": 16
    },
    \"sink\": {
      \"dispatchers\": null,
      \"protocol\": \"default\"
    },
    \"cyclic-replication\": {
      \"enable\": false,
      \"replica-id\": 0,
      \"filter-replica-ids\": null,
      \"id-buckets\": 0,
      \"sync-ddl\": false
    },
    \"scheduler\": {
      \"type\": \"table-number\",
      \"polling-time\": -1
    }
  },
  \"state\": \"normal\",
  \"history\": null,
  \"error\": null,
  \"sync-point-enabled\": false,
  \"sync-point-interval\": 600000000000,
  \"creator-version\": \"v4.0.13\"
}"
}

# Update changefeed checkpoint to given ts.
function update_changefeed_checkpoint() {
	pd_addr=$1
	cfid=$2
	checkpoint_ts=$3
	ETCDCTL_API=3 etcdctl --endpoints=$pd_addr put \
		/tidb/cdc/job/$cfid \
		"{\"resolved-ts\":$checkpoint_ts,\"checkpoint-ts\":$checkpoint_ts,\"admin-job-type\":0}"
}

function get_gc_safepoint() {
	pd_addr=$1
	pd_cluster_id=$2
	val=$(ETCDCTL_API=3 etcdctl --endpoints=$pd_addr get \
		/pd/$pd_cluster_id/gc/safe_point/service/gc_worker |
		grep -oE "\"gc_worker.*safe_point\":[0-9]+" |
		grep -oE "safe_point\":[0-9]+" |
		grep -oE "[0-9]+")
	echo $val
}

function run() {
	rm -rf $WORK_DIR && mkdir -p $WORK_DIR

	start_tidb_cluster --workdir $WORK_DIR

	cd $WORK_DIR

	pd_addr="http://$UP_PD_HOST_1:$UP_PD_PORT_1"
	pd_cluster_id=$(curl -s $pd_addr/pd/api/v1/cluster | grep -oE "id\":\s[0-9]+" | grep -oE "[0-9]+")
	gc_safepoint=$(get_gc_safepoint $pd_addr $pd_cluster_id)
	start_ts=$(($gc_safepoint - 100))

	run_sql_file $CUR/data/prepare.sql ${UP_TIDB_HOST} ${UP_TIDB_PORT}

	TOPIC_NAME="ticdc-split-region-test-$RANDOM"
	case $SINK_TYPE in
	kafka) SINK_URI="kafka://127.0.0.1:9092/$TOPIC_NAME?protocol=open-protocol&partition-num=4&kafka-version=${KAFKA_VERSION}&max-message-bytes=10485760" ;;
	*) SINK_URI="mysql://normal:123456@127.0.0.1:3306/" ;;
	esac

	# To simulate upgrading, we create changefeed manually.
	# A changefeed whose start ts equals to gc safepoint.
	CFID="checkpoint-ts-equals-to-gc-ts"
	create_changefeed_v4013 $pd_addr $CFID $SINK_URI $start_ts
	# set checkpoint to gc safepoint.
	update_changefeed_checkpoint $pd_addr $CFID $gc_safepoint
	if [ "$SINK_TYPE" == "kafka" ]; then
		run_kafka_consumer $WORK_DIR "kafka://127.0.0.1:9092/$TOPIC_NAME?protocol=open-protocol&partition-num=4&version=${KAFKA_VERSION}&max-message-bytes=10485760"
	fi

	run_cdc_server --workdir $WORK_DIR --binary $CDC_BINARY

	# sync_diff can't check non-exist table, so we check expected tables are created in downstream first
	check_table_exists upgrade_gc_safepoint.test1 ${DOWN_TIDB_HOST} ${DOWN_TIDB_PORT}
	check_sync_diff $WORK_DIR $CUR/conf/diff_config.toml

	cleanup_process $CDC_BINARY
}

trap stop_tidb_cluster EXIT
run $*
check_logs $WORK_DIR
echo "[$(date)] <<<<<< run test case $TEST_NAME success! >>>>>>"
